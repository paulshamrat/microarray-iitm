{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of Differentially Expressed Genes and Pathway Analysis in Ovarian Cancer Using Microarray Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the microarray data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "# Define the URL to download the data file\n",
    "url = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE35972&format=file\"\n",
    "\n",
    "# Send a request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the downloaded file\n",
    "file_name = \"GSE35972_RAW.tar\"\n",
    "with open(file_name, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Extract the contents of the TAR file\n",
    "tar = tarfile.open(file_name, \"r\")\n",
    "tar.extractall()\n",
    "extracted_dir = tar.getnames()[0]  # Get the extracted directory name\n",
    "tar.close()\n",
    "\n",
    "# Load the expression data from the extracted files\n",
    "expression_data = pd.DataFrame()\n",
    "for member in tarfile.open(file_name).getmembers():\n",
    "    if member.isfile() and member.name.endswith(\".txt\"):\n",
    "        file = tar.extractfile(member)\n",
    "        sample_id = member.name.split(\".txt\")[0]\n",
    "        sample_data = pd.read_csv(file, sep=\"\\t\", skiprows=2, index_col=0)\n",
    "        expression_data[sample_id] = sample_data[\"VALUE\"]\n",
    "\n",
    "# Print the expression data\n",
    "print(expression_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m expression_data \u001b[39m=\u001b[39m expression_data\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m     10\u001b[0m \u001b[39m# Data normalization\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m normalized_data \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39;49mfit_transform(expression_data)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Convert the normalized data back to a DataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m normalized_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(normalized_data, columns\u001b[39m=\u001b[39mexpression_data\u001b[39m.\u001b[39mcolumns, index\u001b[39m=\u001b[39mexpression_data\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    862\u001b[0m     X,\n\u001b[0;32m    863\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    864\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    865\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    866\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[39m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Transpose the expression data\n",
    "expression_data = expression_data.T\n",
    "\n",
    "# Remove genes with missing values\n",
    "expression_data = expression_data.dropna()\n",
    "\n",
    "# Data normalization\n",
    "normalized_data = StandardScaler().fit_transform(expression_data)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "normalized_data = pd.DataFrame(normalized_data, columns=expression_data.columns, index=expression_data.index)\n",
    "\n",
    "# Perform gene filtering (optional)\n",
    "# filter_expression_data = normalized_data[(normalized_data > threshold).any(axis=1)]\n",
    "\n",
    "# Print the preprocessed data\n",
    "print(normalized_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform differntial expression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the treated and untreated samples\n",
    "treated_samples = df[df[\"Treatment\"] == \"Treated\"].drop(columns=[\"Treatment\"])\n",
    "untreated_samples = df[df[\"Treatment\"] == \"Untreated\"].drop(columns=[\"Treatment\"])\n",
    "\n",
    "# Perform statistical analysis, e.g., t-test\n",
    "_, p_values = ttest_ind(treated_samples, untreated_samples, axis=0)\n",
    "\n",
    "# Adjust p-values for multiple testing using the Benjamini-Hochberg method\n",
    "adjusted_p_values = multipletests(p_values, method='fdr_bh')[1]\n",
    "\n",
    "# Identify differentially expressed genes based on a significance threshold (e.g., 0.05)\n",
    "significance_threshold = 0.05\n",
    "differentially_expressed_genes = df.columns[:-1][adjusted_p_values < significance_threshold]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform pathway enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pathway enrichment analysis using Reactome database (via Enrichr API)\n",
    "enrichr_url = \"https://maayanlab.cloud/Enrichr/enrich\"\n",
    "genes_str = \"\\n\".join(differentially_expressed_genes)\n",
    "payload = {\n",
    "    \"list\": (None, genes_str),\n",
    "    \"backgroundType\": (None, \"genes\"),\n",
    "    \"dataset\": (None, \"Reactome_2016\")\n",
    "}\n",
    "response = requests.post(enrichr_url, files=payload)\n",
    "\n",
    "# Retrieve the enriched pathways\n",
    "enrichment_results = response.json()\n",
    "enriched_pathways = enrichment_results[\"Reactome_2016\"]\n",
    "\n",
    "# Print the enriched pathways\n",
    "for pathway in enriched_pathways:\n",
    "    print(pathway)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Volcano plot\n",
    "fold_changes = treated_samples.mean() - untreated_samples.mean()\n",
    "plt.scatter(fold_changes, -np.log10(adjusted_p_values))\n",
    "plt.xlabel('Fold Change')\n",
    "plt.ylabel('-log10(Adjusted p-value)')\n",
    "plt.title('Volcano Plot')\n",
    "plt.show()\n",
    "\n",
    "# Example: Gene expression distribution by treatment status\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Treatment', y=differentially_expressed_genes[0], data=df)\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('Gene Expression')\n",
    "plt.title('Gene Expression Distribution by Treatment')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
